from flask import Flask, request, jsonify
from openai import OpenAI
import os
import base64
import datetime
from dotenv import load_dotenv
from context_information import cctv_locations, manpower_available, layout_of_mall, fire_alarm_stations, fire_management_SOP
import asyncio

# Load environment variables from .env file
load_dotenv()

app = Flask(__name__)

# Utility function to encode an image file in base64
def encode_image_file(image_file):
    return base64.b64encode(image_file.read()).decode("utf-8")

# Create the OpenAI client using your API key from the environment variables
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

@app.route('/image_context', methods=['POST'])
def analyze_image():
    # Check if the image is provided in the request
    if 'image' not in request.files:
        return jsonify({"error": "No image provided. Use form-data with key 'image'."}), 400

    image_file = request.files['image']
    if image_file.filename == '':
        return jsonify({"error": "Empty image file provided."}), 400

    # Get the CCTV number from the request form data
    cctv_number = request.form.get('cctv_number')
    if not cctv_number:
        return jsonify({"error": "CCTV number not provided."}), 400

    # Validate the provided CCTV number exists in our mapping
    if cctv_number not in cctv_locations:
        return jsonify({"error": f"Invalid CCTV number: {cctv_number}"}), 400

    # Retrieve the location based on the CCTV number
    location_of_fire = cctv_locations[cctv_number]

    # Get current timestamp (without microseconds)
    datetime_now = datetime.datetime.now().replace(microsecond=0)

    # Encode the uploaded image to base64
    base64_image = encode_image_file(image_file)

    # Create the messages payload for the OpenAI Chat API call
    messages = [
        {
            "role": "user",
            "content": [
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"},
                },
                {
                    "type": "text",
                    "text": f"""
                    This is a snapshot of a shopping mall from the CCTV. A machine learning model has deemed that there is a fire present in the image. You are to verify if there is indeed a fire. 
                    
                    If there is a fire detected in the image, describe and elaborate what is happening in the image strictly using the format below:

                    1) Size of fire
                    - There is a <small/medium/large> fire detected at {location_of_fire} on {datetime_now}. It is about <insert size of fire> square metres in size.  
                    2) Nature of fire
                    - The fire is likely to be of <nature> (e.g. electrical, chemical, etc.) nature.
                    3) Location of the fire
                    - The fire is located at <location>.
                    4) General situation
                    - <Describe the general situation>.

                    If there is no fire or detected, strictly only return "There is no fire or smoke detected."

                    Strictly adhere to the format above, do not include any headers, introduction or conclusion.
                    """
                }
            ]
        }
    ]

    try:
        # Call the OpenAI Chat Completions API
        completion = client.chat.completions.create(
            model="gpt-4o",
            messages=messages
        )
        # Extract the response text from the API's reply
        response_content = completion.choices[0].message.content

        return jsonify({"response": response_content})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/generate_solution', methods=['POST'])
def generate_solution():

    # Extract the context generated by the /image_context endpoint from the request JSON
    data = request.get_json()
    image_context = data.get("context")
    if not image_context:
        return jsonify({"error": "No image context provided. Please include 'context' in your JSON payload."}), 400
    

    try:
        # Define the content payload for generating the solution
        content = [
            {
                "type": "text",
                "text": f"""
                        You are the head of security at the shopping mall. 
                        
                        You have been alerted to a potential fire through the CCTV system. 
                        
                        You are to come up with detailed actionable steps using each security guard's name to manage the situation with the security team with reference to the fire response and management SOP, context of the fire, and the manpower available, following the exact format below, do not include any headers, introduction or conclusion:

                        # Fire Response and Management Plan

                        There are <insert number of security guards present> security guards and <insert number of security managers present> security manager on duty today.
                        The security guards are as follows: <names of security guards, separated by commas>.
                        The security manager is <name of security manager>.

                        <Insert summary of the situation based on the context provided>

                        In response to the fire detected at <insert location of fire> on <insert date and time fire started>, here is a step-by-step plan for managing the situation based on the given SOP, fire context, and available manpower:

                        ## Phase 1: Immediate Detection & Initial Response (0–1 Minute)
                        <insert steps based on the SOP, contextualized to the situation>

                        ## Phase 2: Emergency Communication & Service Contact (1–2 Minutes)
                        <insert steps based on the SOP, contextualized to the situation>

                        ## Phase 3: Evacuation Coordination (2–5 Minutes)
                        <insert steps based on the SOP, contextualized to the situation>

                        ## Phase 4: On-Site Fire Suppression (If Safe and Trained) (0–10 Minutes)
                        <insert steps based on the SOP, contextualized to the situation>

                        ## Phase 5: Ongoing Communication & Coordination (Throughout Incident)
                        <insert steps based on the SOP, contextualized to the situation>

                        ## Phase 6: Securing the Premises & Post-Incident Procedures (After 10 Minutes)
                        <insert steps based on the SOP, contextualized to the situation>

                        
                        Here are the details you need to consider:
                        The context of the fire is as follows: {image_context}
                        The manpower available is as follows: {manpower_available}
                        The layout of the mall is as follows: {layout_of_mall}
                        The fire alarm stations are as follows: {fire_alarm_stations}
                        The fire management SOP is as follows: {fire_management_SOP}
                    """
            }
        ]

        # Call the OpenAI Chat Completions API
        completion = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "user",
                    "content": content
                }
            ]
        )

        response_content = completion.choices[0].message.content

        return jsonify({"response": response_content})
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route('/ask', methods=['POST'])
def ask():
    # Expecting a JSON payload with 'conversation' (list of messages) and 'question' (string)
    data = request.get_json()
    if not data:
        return jsonify({"error": "Invalid JSON payload."}), 400

    conversation = data.get("conversation")
    question = data.get("question")
    initial_solution = data.get("initial_solution")
    
    if conversation is None or question is None:
        return jsonify({"error": "Please provide both 'conversation' and 'question' fields."}), 400

    # Ensure the conversation is a list
    if not isinstance(conversation, list):
        return jsonify({"error": "'conversation' must be a list of message objects."}), 400

    # Define a default system prompt
    default_system_prompt = f"""
        You are an AI assistant helping with dealing with a fire incident at a shopping mall.
        The user is a security officer seeking guidance on managing the situation and has been provided with a preliminary solution.
        The user might ask follow-up questions or seek clarification on the provided solution.
        Please provide detailed and informative responses to assist the user effectively.

        If the user asks a question or provides context that challenges the newest provided solution, please modify the solution accordingly and inform the user.
        This could be a new development in the situation, a change in the manpower available, blockage of certain exits, or any other relevant information.

        If the user asks for a new solution, generate a new solution based on the updated context and provide it to the user. Do not mention the previous solution in the new response, rather, provide the updated solution as if it is the first time.

        This is a dynamic conversation, and you should adapt your responses based on the user's queries and the context of the conversation.

        Here is the initial solution provided to the user: {initial_solution}
        The original manpower available is as follows: {manpower_available}
        The original layout of the mall is as follows: {layout_of_mall}
        The original fire alarm stations are as follows: {fire_alarm_stations}
        The fire management SOP is as follows: {fire_management_SOP}
    """

    # Prepend the system prompt if it's not already the first message
    if len(conversation) == 0 or conversation[0].get("role") != "system":
        conversation.insert(0, {"role": "system", "content": default_system_prompt})

    # Append the new question as a user message
    conversation.append({"role": "user", "content": question})
    
    try:
        # Call the OpenAI Chat Completions API with the full conversation
        completion = client.chat.completions.create(
            model="gpt-4o",
            messages=conversation
        )
        # Get the assistant's response and append it to the conversation
        response_message = completion.choices[0].message.content
        conversation.append({"role": "assistant", "content": response_message})
        
        # Return the updated conversation thread
        return jsonify({"conversation": conversation})
    except Exception as e:
        return jsonify({"error": str(e)}), 500
    

############################################################
# --- Helper functions for snapshot to solution pipeline ---
############################################################

def process_snapshot_sync(snapshot: list) -> str:
    """
    Process a single snapshot using the logic from the /image_context endpoint.
    Expects snapshot to be a list: [base64_image, cctv_number, timestamp].
    Uses the provided timestamp instead of the current datetime.
    """
    base64_image, cctv_number, timestamp = snapshot

    # Validate CCTV number
    if cctv_number not in cctv_locations:
        raise Exception(f"Invalid CCTV number: {cctv_number}")

    location_of_fire = cctv_locations[cctv_number]

    # Build the messages payload similar to /image_context but using the provided timestamp
    messages = [
        {
            "role": "user",
            "content": [
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"},
                },
                {
                    "type": "text",
                    "text": f"""
                            This is a snapshot of a shopping mall from the CCTV. A machine learning model has deemed that there is a fire present in the image. You are to verify if there is indeed a fire. 

                            If there is a fire detected in the image, describe and elaborate what is happening in the image strictly using the format below:

                            1) Size of fire
                            - There is a <small/medium/large> fire detected at {location_of_fire} on {timestamp}. It is about <insert size of fire> square metres in size.  
                            2) Nature of fire
                            - The fire is likely to be of <nature> (e.g. electrical, chemical, etc.) nature.
                            3) Location of the fire
                            - The fire is located at <location>.
                            4) General situation
                            - <Describe the general situation>.

                            If there is no fire or smoke detected, strictly only return "There is no fire or smoke detected."

                            Strictly adhere to the format above, do not include any headers, introduction or conclusion.
                            """
                }
            ]
        }
    ]

    # Call the OpenAI Chat Completions API
    completion = client.chat.completions.create(
        model="gpt-4o",
        messages=messages
    )
    response_content = completion.choices[0].message.content
    return response_content

def summarize_contexts(contexts : list) -> str:
    """
    Summarize a list of image contexts (already in chronological order) into one summary.
    """
    combined_contexts = "\n".join(contexts)
    print("Combined contexts:", combined_contexts)
    print("\n")
    prompt = f"Based on the following chronological snapshots of a fire incident, summarise what has happened over time in a concise manner:\n{combined_contexts}"
    messages = [{"role": "user", "content": prompt}]
    completion = client.chat.completions.create(
        model="gpt-4o",
        messages=messages
    )
    summary = completion.choices[0].message.content


    print("Summary of the situation based on the provided snapshots:", summary)
    print("\n")
    return summary

def generate_solution_from_summary(summary : str) -> str:
    """
    Generate a fire management solution using the summarised context.
    This function replicates the logic from the /generate_solution endpoint.
    """
    content = [
        {
            "type": "text",
            "text": f"""
                    You are the head of security at the shopping mall. 

                    You have been alerted to a potential fire through the CCTV system. 

                    You are to come up with detailed actionable steps using each security guard's name to manage the situation with the security team with reference to the fire response and management SOP, context of the fire, and the manpower available.
                    Following the exact format below, do not include any headers, introduction or conclusion, omit or modify the phases and steps as needed:

                    # Fire Response and Management Plan

                    There are <insert number of security guards present> security guards and <insert number of security managers present> security manager on duty today.
                    The security guards are as follows: <names of security guards, separated by commas>.
                    The security manager is <name of security manager>.

                    <Insert summary of the situation based on the context provided>

                    In response to the fire detected at <insert location of fire> on <insert date and time fire started>, here is a step-by-step plan for managing the situation based on the given SOP, fire context, and available manpower:

                    ## Phase 1: Immediate Detection & Initial Response (0–1 Minute)
                    <insert steps based on the SOP, contextualized to the situation>

                    ## Phase 2: Emergency Communication & Service Contact (1–2 Minutes)
                    <insert steps based on the SOP, contextualized to the situation>

                    ## Phase 3: Evacuation Coordination (2–5 Minutes)
                    <insert steps based on the SOP, contextualized to the situation>

                    ## Phase 4: On-Site Fire Suppression (If Safe and Trained) (0–10 Minutes)
                    <insert steps based on the SOP, contextualized to the situation>

                    ## Phase 5: Ongoing Communication & Coordination (Throughout Incident)
                    <insert steps based on the SOP, contextualized to the situation>

                    ## Phase 6: Securing the Premises & Post-Incident Procedures (After 10 Minutes)
                    <insert steps based on the SOP, contextualized to the situation>

                    Here are the details you need to consider:
                    The context of the fire is as follows: {summary}
                    The manpower available is as follows: {manpower_available}
                    The layout of the mall is as follows: {layout_of_mall}
                    The fire alarm stations are as follows: {fire_alarm_stations}
                    The fire management SOP is as follows: {fire_management_SOP}
                    """
        }
    ]
    messages = [
        {
            "role": "user",
            "content": content
        }
    ]
    completion = client.chat.completions.create(
        model="gpt-4o",
        messages=messages
    )
    response_content = completion.choices[0].message.content
    return response_content

async def process_snapshots(snapshots : list) -> str:
    """
    Asynchronously process all snapshots:
      - Process each image snapshot concurrently.
      - If more than one snapshot, summarise the chronological contexts.
      - Generate a solution based on the summarised context.
    """
    # Process each snapshot concurrently (using asyncio.to_thread to run the blocking API calls)
    tasks = [asyncio.to_thread(process_snapshot_sync, snapshot) for snapshot in snapshots]
    contexts = await asyncio.gather(*tasks)

    # If more than one image, summarise the overall situation; else use the single context.
    if len(contexts) > 1:
        summary = await asyncio.to_thread(summarize_contexts, contexts)
    else:
        summary = contexts[0]

    # Generate a solution using the summarised context
    solution = await asyncio.to_thread(generate_solution_from_summary, summary)
    return solution

# --- New Endpoint ---

@app.route('/snapshot_to_solution', methods=['POST'])
def snapshot_to_solution():
    """
    This endpoint accepts a JSON payload with the following format:
    {
        "snapshots" : [
            [base64_image_1, cctv_number_of_image_1, timestamp_of_image_1],
            [base64_image_2, cctv_number_of_image_2, timestamp_of_image_2],
            [base64_image_3, cctv_number_of_image_3, timestamp_of_image_3]
        ]
    }

    The snapshots are:
      1. Sorted by timestamp in ascending order.
      2. Each processed asynchronously using the image_context logic (with the provided timestamp).
      3. Optionally summarised (if more than one image) to capture the overall progression.
      4. Used to generate a corresponding solution using the generate_solution logic.
    The final output is the generated solution.
    """
    data = request.get_json()
    if not data or "snapshots" not in data:
        return jsonify({"error": "No snapshots provided in JSON payload."}), 400

    snapshots = data["snapshots"]
    if not isinstance(snapshots, list):
        return jsonify({"error": "Snapshots must be a list of lists."}), 400

    try:
        # Sort snapshots by the provided timestamp (assumed to be in a comparable format)
        sorted_snapshots = sorted(snapshots, key=lambda x: x[2])
        # Process snapshots asynchronously and generate the solution
        solution = asyncio.run(process_snapshots(sorted_snapshots))
        return jsonify({"solution": solution})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)
